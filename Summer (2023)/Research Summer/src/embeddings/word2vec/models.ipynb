{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "model_name = 'word2vec-google-news-300'\n",
    "# wv_path = api.load(model_name, return_path=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bardanik/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n"
     ]
    }
   ],
   "source": [
    "print(wv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = api.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'London'\t'Paris'\t0.53\n",
      "'London'\t'bicycle'\t0.08\n",
      "'capital'\t'London'\t0.21\n",
      "'London'\t'Moscow'\t0.43\n",
      "'Paris'\t'capital'\t0.20\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    ('London', 'Paris'),\n",
    "    ('London', 'bicycle'),\n",
    "    ('capital', 'London'),\n",
    "    ('London', 'Moscow'),\n",
    "    ('Paris', 'capital'),\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity(w1, w2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyedVectors<vector_size=300, 3000000 keys>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cats', 0.8099379539489746), ('dog', 0.760945737361908), ('kitten', 0.7464984655380249), ('feline', 0.7326233983039856), ('beagle', 0.7150582671165466), ('puppy', 0.7075453996658325), ('pup', 0.6934291124343872), ('pet', 0.6891531348228455), ('felines', 0.6755931377410889), ('chihuahua', 0.6709762215614319)]\n",
      "[('cats', 0.8099379539489746), ('dog', 0.760945737361908), ('kitten', 0.7464984655380249), ('feline', 0.7326233983039856), ('beagle', 0.7150582671165466), ('puppy', 0.7075453996658325), ('pup', 0.6934291124343872), ('pet', 0.6891531348228455), ('felines', 0.6755931377410889), ('chihuahua', 0.6709762215614319)]\n"
     ]
    }
   ],
   "source": [
    "print(wv.similar_by_word(\"cat\"))\n",
    "print(wv.similar_by_key(\"cat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    @staticmethod\n",
      "    def cosine_similarities(vector_1, vectors_all):\n",
      "        \"\"\"Compute cosine similarities between one vector and a set of other vectors.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        vector_1 : numpy.ndarray\n",
      "            Vector from which similarities are to be computed, expected shape (dim,).\n",
      "        vectors_all : numpy.ndarray\n",
      "            For each row in vectors_all, distance from vector_1 is computed, expected shape (num_vectors, dim).\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        numpy.ndarray\n",
      "            Contains cosine distance between `vector_1` and each row in `vectors_all`, shape (num_vectors,).\n",
      "\n",
      "        \"\"\"\n",
      "        norm = np.linalg.norm(vector_1)\n",
      "        all_norms = np.linalg.norm(vectors_all, axis=1)\n",
      "        dot_products = dot(vectors_all, vector_1)\n",
      "        similarities = dot_products / (norm * all_norms)\n",
      "        return similarities\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import gensim\n",
    "# print(inspect.getsource(wv.similarity))\n",
    "# print(inspect.getsource(gensim.matutils.unitvec))\n",
    "print(inspect.getsource(wv.cosine_similarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.8908596\n",
      "0.76094574 vs 0.7609458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.7609457], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "wv_1 = wv['cat']\n",
    "wv_2 = wv['dog']\n",
    "\n",
    "product = np.dot(wv_1, wv_2)\n",
    "\n",
    "wv_1_norm = np.linalg.norm(wv_1)\n",
    "wv_2_norm = np.linalg.norm(wv_2)\n",
    "\n",
    "print(product)\n",
    "\n",
    "normalized_product = np.dot(wv_1/wv_1_norm, wv_2/wv_2_norm)\n",
    "\n",
    "print(wv.similarity('cat', 'dog'),'vs',normalized_product)\n",
    "\n",
    "wv.cosine_similarities(wv_1, [wv_2]) # also computes cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying now to implement first snippet of algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from collections import Counter\n",
    "import string\n",
    "from pprint import pprint\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load pre-trained Word2Vec model. Here I'm using Google's model, which you can download from\n",
    "# https://code.google.com/archive/p/word2vec/\n",
    "# Please note that this model is 1.5GB in size\n",
    "# model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "text = \"Animals are multicellular eukaryotic organisms that form the biological kingdom Animalia. With few exceptions, animals consume organic material, breathe oxygen, are able to move, reproduce sexually, and grow from a hollow sphere of cells, the blastula, during embryonic development. Over 1.5 million living animal species have been described—of which around 1 million are insects—but it has been estimated there are over 7 million animal species in total. Animals range in size from 8.5 micrometres to 33.6 metres. They have complex interactions with each other and their environments, forming intricate food webs. The study of animals is called zoology.\"\n",
    "keyword = \"animal\"\n",
    "threshold = 0.5  # set your similarity threshold here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Animals',\n",
      "  'are',\n",
      "  'multicellular',\n",
      "  'eukaryotic',\n",
      "  'organisms',\n",
      "  'that',\n",
      "  'form',\n",
      "  'the',\n",
      "  'biological',\n",
      "  'kingdom',\n",
      "  'Animalia',\n",
      "  '.'],\n",
      " ['With',\n",
      "  'few',\n",
      "  'exceptions',\n",
      "  ',',\n",
      "  'animals',\n",
      "  'consume',\n",
      "  'organic',\n",
      "  'material',\n",
      "  ',',\n",
      "  'breathe',\n",
      "  'oxygen',\n",
      "  ',',\n",
      "  'are',\n",
      "  'able',\n",
      "  'to',\n",
      "  'move',\n",
      "  ',',\n",
      "  'reproduce',\n",
      "  'sexually',\n",
      "  ',',\n",
      "  'and',\n",
      "  'grow',\n",
      "  'from',\n",
      "  'a',\n",
      "  'hollow',\n",
      "  'sphere',\n",
      "  'of',\n",
      "  'cells',\n",
      "  ',',\n",
      "  'the',\n",
      "  'blastula',\n",
      "  ',',\n",
      "  'during',\n",
      "  'embryonic',\n",
      "  'development',\n",
      "  '.'],\n",
      " ['Over',\n",
      "  '1.5',\n",
      "  'million',\n",
      "  'living',\n",
      "  'animal',\n",
      "  'species',\n",
      "  'have',\n",
      "  'been',\n",
      "  'described—of',\n",
      "  'which',\n",
      "  'around',\n",
      "  '1',\n",
      "  'million',\n",
      "  'are',\n",
      "  'insects—but',\n",
      "  'it',\n",
      "  'has',\n",
      "  'been',\n",
      "  'estimated',\n",
      "  'there',\n",
      "  'are',\n",
      "  'over',\n",
      "  '7',\n",
      "  'million',\n",
      "  'animal',\n",
      "  'species',\n",
      "  'in',\n",
      "  'total',\n",
      "  '.'],\n",
      " ['Animals',\n",
      "  'range',\n",
      "  'in',\n",
      "  'size',\n",
      "  'from',\n",
      "  '8.5',\n",
      "  'micrometres',\n",
      "  'to',\n",
      "  '33.6',\n",
      "  'metres',\n",
      "  '.'],\n",
      " ['They',\n",
      "  'have',\n",
      "  'complex',\n",
      "  'interactions',\n",
      "  'with',\n",
      "  'each',\n",
      "  'other',\n",
      "  'and',\n",
      "  'their',\n",
      "  'environments',\n",
      "  ',',\n",
      "  'forming',\n",
      "  'intricate',\n",
      "  'food',\n",
      "  'webs',\n",
      "  '.'],\n",
      " ['The', 'study', 'of', 'animals', 'is', 'called', 'zoology', '.']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tokenize the text into sentences and then into words\n",
    "sentences = sent_tokenize(text)\n",
    "words_lists = [word_tokenize(sentence) for sentence in sentences]\n",
    "pprint(words_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['animals',\n",
      " 'are',\n",
      " 'multicellular',\n",
      " 'eukaryotic',\n",
      " 'organisms',\n",
      " 'that',\n",
      " 'form',\n",
      " 'the',\n",
      " 'biological',\n",
      " 'kingdom',\n",
      " 'animalia',\n",
      " 'with',\n",
      " 'few',\n",
      " 'exceptions',\n",
      " 'consume',\n",
      " 'organic',\n",
      " 'material',\n",
      " 'breathe',\n",
      " 'oxygen',\n",
      " 'able',\n",
      " 'to',\n",
      " 'move',\n",
      " 'reproduce',\n",
      " 'sexually',\n",
      " 'and',\n",
      " 'grow',\n",
      " 'from',\n",
      " 'a',\n",
      " 'hollow',\n",
      " 'sphere',\n",
      " 'of',\n",
      " 'cells',\n",
      " 'blastula',\n",
      " 'during',\n",
      " 'embryonic',\n",
      " 'development',\n",
      " 'over',\n",
      " '1.5',\n",
      " 'million',\n",
      " 'living',\n",
      " 'animal',\n",
      " 'species',\n",
      " 'have',\n",
      " 'been',\n",
      " 'described—of',\n",
      " 'which',\n",
      " 'around',\n",
      " '1',\n",
      " 'insects—but',\n",
      " 'it',\n",
      " 'has',\n",
      " 'estimated',\n",
      " 'there',\n",
      " '7',\n",
      " 'in',\n",
      " 'total',\n",
      " 'range',\n",
      " 'size',\n",
      " '8.5',\n",
      " 'micrometres',\n",
      " '33.6',\n",
      " 'metres',\n",
      " 'they',\n",
      " 'complex',\n",
      " 'interactions',\n",
      " 'each',\n",
      " 'other',\n",
      " 'their',\n",
      " 'environments',\n",
      " 'forming',\n",
      " 'intricate',\n",
      " 'food',\n",
      " 'webs',\n",
      " 'study',\n",
      " 'is',\n",
      " 'called',\n",
      " 'zoology']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Flatten the list of words and remove punctuation and duplicates\n",
    "flat_words = [word for sublist in words_lists for word in sublist]\n",
    "filtered_words = [word.lower() for word in flat_words if word not in string.punctuation]\n",
    "unique_words = list(Counter(filtered_words)) # We use here Counter, because it gives words that are in the same order as in the text, because while words are keys, their order in the text is the mapped value.\n",
    "pprint(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches: ['animal']\n",
      "not_found: ['animalia', 'to', 'and', 'a', 'of', 'blastula', '1.5', 'described—of', 'insects—but', '8.5', '33.6', 'metres']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate similarity scores and find matches\n",
    "matches = []\n",
    "not_in_vocab = []\n",
    "\n",
    "threshold = 0.8\n",
    "for word in unique_words:\n",
    "    if word in wv:\n",
    "        similarity = wv.similarity(word, keyword)\n",
    "        if similarity > threshold:\n",
    "            matches.append(word)\n",
    "    else:\n",
    "        not_in_vocab.append(word)\n",
    "\n",
    "print(f\"matches: {matches}\", f\"not_found: {not_in_vocab}\", sep=\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_highlighted = text\n",
    "for match in matches:\n",
    "    text_highlighted = re.sub(r'\\b' + match + r'\\b', '**' + str.upper(match) + '**', text_highlighted, flags=re.IGNORECASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Animals are multicellular eukaryotic organisms that form the biological kingdom Animalia. With few exceptions, animals consume organic material, breathe oxygen, are able to move, reproduce sexually, and grow from a hollow sphere of cells, the blastula, during embryonic development. Over 1.5 million living **ANIMAL** species have been described—of which around 1 million are insects—but it has been estimated there are over 7 million **ANIMAL** species in total. Animals range in size from 8.5 micrometres to 33.6 metres. They have complex interactions with each other and their environments, forming intricate food webs. The study of animals is called zoology."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(text_highlighted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vylet-ner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
